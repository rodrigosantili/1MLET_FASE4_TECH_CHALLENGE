{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar para exibir mais colunas e linhas no terminal\n",
    "pd.set_option('display.max_rows', None)  # Exibir todas as linhas\n",
    "pd.set_option('display.max_columns', None)  # Exibir todas as colunas\n",
    "pd.set_option('display.width', None)  # Ajusta a largura para não quebrar\n",
    "pd.set_option('display.expand_frame_repr', False)  # Evita a quebra de colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coleta dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificar a ação\n",
    "symbol = 'NVDA' #ou outra empresa de sua escolha\n",
    "start_date = '2014-01-01'\n",
    "end_date = '2024-12-20'\n",
    "\n",
    "# Baixar os dados\n",
    "df = yf.download(symbol, start=start_date, end=end_date)\n",
    "\n",
    "# Visualizar os primeiros dados\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desenvolvimento do Modelo LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento dos Dados\n",
    "Precisamos normalizar os dados e preparar a série temporal para ser utilizada pelo modelo LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Selecionar apenas a coluna de \"Close\" (valor de fechamento)\n",
    "data = df[['Close']]\n",
    "\n",
    "# Normalizar os dados entre 0 e 1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Dividir os dados em treino e teste (80% para treino e 20% para teste)\n",
    "train_size = int(len(scaled_data) * 0.8)\n",
    "train_data = scaled_data[:train_size]\n",
    "test_data = scaled_data[train_size:]\n",
    "\n",
    "# Função para criar o dataset em janelas temporais\n",
    "def create_dataset(data, window_size):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(window_size, len(data)):\n",
    "        x.append(data[i-window_size:i, 0])\n",
    "        y.append(data[i, 0])\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "# Definir o tamanho da janela temporal\n",
    "window_size = 60\n",
    "x_train, y_train = create_dataset(train_data, window_size)\n",
    "x_test, y_test = create_dataset(test_data, window_size)\n",
    "\n",
    "# Reshape para [samples, time steps, features] (necessário para o LSTM)\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construção e Treinamento do Modelo LSTM\n",
    "Aqui, vamos criar o modelo de rede neural utilizando Keras com LSTM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Criar o modelo\n",
    "model = Sequential()\n",
    "\n",
    "# Adicionar camadas LSTM\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Camada de saída\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação do Modelo\n",
    "Depois de treinar, podemos avaliar o modelo nos dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer as previsões\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Inverter a normalização para trazer os dados de volta à escala original\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test_unscaled = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Avaliar com RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = np.sqrt(mean_squared_error(y_test_unscaled, predictions))\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvamento e Exportação do Modelo\n",
    "Agora, salvamos o modelo treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lstm_stock_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy do Modelo em uma API\n",
    "Vamos criar uma API utilizando Flask para servir o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Carregar o modelo treinado\n",
    "model = load_model('lstm_stock_model.h5')\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Definir a rota para fazer previsões\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Receber os dados históricos do cliente\n",
    "    data = request.json['data']\n",
    "    data = np.array(data).reshape(-1, 1)\n",
    "    \n",
    "    # Normalizar os dados recebidos\n",
    "    scaled_data = scaler.transform(data)\n",
    "    \n",
    "    # Preparar os dados para o modelo (usando uma janela de 60 dias)\n",
    "    x_input = scaled_data[-60:].reshape(1, 60, 1)\n",
    "    \n",
    "    # Fazer a previsão\n",
    "    prediction = model.predict(x_input)\n",
    "    \n",
    "    # Inverter a normalização da previsão\n",
    "    predicted_price = scaler.inverse_transform(prediction)\n",
    "    \n",
    "    return jsonify({'predicted_price': predicted_price[0][0]})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
